{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = False  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = False  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd"
      },
      "outputs": [],
      "source": [
        "# Checkpoints\n",
        "# Following this guide: https://civitai.com/models/1301129?modelVersionId=1523907\n",
        "\n",
        "use_fast_model = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if use_fast_model:\n",
        "  !wget -c -nc https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_1.3B_bf16.safetensors -P ./models/diffusion_models/\n",
        "elif True:\n",
        "  !wget -c -nc https://huggingface.co/city96/Wan2.1-T2V-14B-gguf/resolve/main/wan2.1-t2v-14b-Q4_K_M.gguf -P ./models/diffusion_models/\n",
        "\n",
        "!wget -c -nc https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors -P ./models/clip/\n",
        "!wget -c -nc https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors -P ./models/clip_vision\n",
        "!wget -c -nc https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors -P ./models/vae/\n",
        "\n",
        "!git clone https://github.com/yolain/ComfyUI-Easy-Use ./custom_nodes/ComfyUI-Easy-Use\n",
        "!pip install -r ./custom_nodes/ComfyUI-Easy-Use/requirements.txt\n",
        "\n",
        "!git clone https://github.com/kijai/ComfyUI-Florence2 ./custom_nodes/ComfyUI-Florence2\n",
        "!pip install -r ./custom_nodes/ComfyUI-Florence2/requirements.txt\n",
        "\n",
        "!git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite ./custom_nodes/ComfyUI-VideoHelperSuite\n",
        "!pip install -r ./custom_nodes/ComfyUI-VideoHelperSuite/requirements.txt\n",
        "\n",
        "!git clone https://github.com/Fannovel16/ComfyUI-Frame-Interpolation ./custom_nodes/ComfyUI-Frame-Interpolation\n",
        "!pip install.py\n",
        "\n",
        "!git clone https://github.com/kijai/ComfyUI-KJNodes ./custom_nodes/ComfyUI-KJNodes\n",
        "!pip install -r ./custom_nodes/ComfyUI-KJNodes/requirements.txt\n",
        "\n",
        "!git clone https://github.com/city96/ComfyUI-GGUF ./custom_nodes/ComfyUI-GGUF\n",
        "!pip install -r ./custom_nodes/ComfyUI-GGUF/requirements.txt\n",
        "\n",
        "!git clone https://github.com/kijai/ComfyUI-GIMM-VFI ./custom_nodes/ComfyUI-GIMM-VFI\n",
        "!pip install -r ./custom_nodes/ComfyUI-GIMM-VFI/requirements.txt\n",
        "\n",
        "!git clone https://github.com/rgthree/rgthree-comfy ./custom_nodes/rgthree-comfy\n",
        "!pip install -r ./custom_nodes/rgthree-comfy/requirements.txt\n",
        "\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Impact-Pack ./custom_nodes/ComfyUI-Impact-Pack\n",
        "!pip install -r ./custom_nodes/ComfyUI-Impact-Pack/requirements.txt\n",
        "\n",
        "!git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts ./custom_nodes/ComfyUI-Custom-Scripts\n",
        "\n",
        "!git clone https://github.com/facok/ComfyUI-HunyuanVideoMultiLora ./custom_nodes/ComfyUI-HunyuanVideoMultiLora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "outputId": "78221d3a-76c3-45c1-b9d0-2897bf7b5d65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got prompt\n",
            "Failed to validate prompt for output 74:\n",
            "* UpscaleModelLoader 96:0:\n",
            "  - Value not in list: model_name: '4x_foolhardy_Remacri.pth' not in []\n",
            "Output will be ignored\n",
            "Failed to validate prompt for output 75:\n",
            "Output will be ignored\n",
            "!!! Exception during processing !!! Error while deserializing header: HeaderTooLarge\n",
            "\n",
            "File path: /content/ComfyUI/models/vae/wan_2.1_vae.safetensors\n",
            "\n",
            "The safetensors file is corrupt or invalid. Make sure this is actually a safetensors file and not a ckpt or pt or other filetype.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 55, in load_torch_file\n",
            "    with safetensors.safe_open(ckpt, framework=\"pt\", device=device.type) as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 327, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 202, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 771, in load_vae\n",
            "    sd = comfy.utils.load_torch_file(vae_path)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 65, in load_torch_file\n",
            "    raise ValueError(\"{}\\n\\nFile path: {}\\n\\nThe safetensors file is corrupt or invalid. Make sure this is actually a safetensors file and not a ckpt or pt or other filetype.\".format(message, ckpt))\n",
            "ValueError: Error while deserializing header: HeaderTooLarge\n",
            "\n",
            "File path: /content/ComfyUI/models/vae/wan_2.1_vae.safetensors\n",
            "\n",
            "The safetensors file is corrupt or invalid. Make sure this is actually a safetensors file and not a ckpt or pt or other filetype.\n",
            "\n",
            "Prompt executed in 0.03 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/main.py\", line 304, in <module>\n",
            "    event_loop.run_until_complete(x)\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
            "    self.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/main.py\", line 306, in <module>\n",
            "    logging.info(\"\\nStopped server\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 2133, in info\n",
            "    def info(msg, *args, **kwargs):\n",
            "    \n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "use_cpu = False # @param {\"type\":\"boolean\"}\n",
        "use_gpu = !use_cpu\n",
        "\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "if use_cpu:\n",
        "  !python main.py --dont-print-server --cpu --use-split-cross-attention\n",
        "\n",
        "elif use_gpu:\n",
        "  !python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import threading\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}